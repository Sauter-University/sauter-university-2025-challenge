# Sauter University 2025 Challenge â€” Plataforma de Dados e ML/Agentes na Google Cloud

![Architecture](./doc/challenge/img/university.drawio.png)

> Plataforma completa de dados na Google Cloud para ingestÃ£o, processamento e exposiÃ§Ã£o de dados de reservatÃ³rios do ONS atravÃ©s de API REST, com anÃ¡lise avanÃ§ada via modelo preditivo ou sistema multi-agente com RAG.

## ğŸ“‹ Resumo Executivo

Este projeto desenvolve uma soluÃ§Ã£o end-to-end na Google Cloud Platform que:

1. **Ingere dados** de reservatÃ³rios do ONS (Operador Nacional do Sistema ElÃ©trico)
2. **Processa** via pipeline GCP (Cloud Storage + BigQuery)  
3. **ExpÃµe** dados atravÃ©s de API REST em Python (FastAPI)
4. **Implementa** modelo de Machine Learning para previsÃ£o de ENA
5. **Visualiza** atravÃ©s de dashboard analÃ­tico no Looker Studio
6. **Garante** observabilidade, seguranÃ§a e controle de custos (budget R$ 300)

### ğŸ¯ Objetivos e KPIs
- **AcurÃ¡cia do modelo ML**: > 70% para previsÃ£o de ENA
- **Cobertura de testes**: â‰¥ 85%
- **OrÃ§amento**: MÃ¡ximo R$ 300 com alertas configurados
- **SLO API**: p95 < 500ms, erro < 1%

## ğŸ‘¥ Equipe

| Nome | GitHub | Responsabilidade |
|------|---------|------------------|
| Genildo Burgos Barros | [@genildoburgos](https://github.com/genildoburgos) | Infraestrutura |
| Gustavo Ferreira Wanderley | [@MESTREGUGABr](https://github.com/MESTREGUGABr) | Engenheiro de Dados |
| Magno Silas Nunes Ramos | [@magnosillas](https://github.com/magnosillas) | Machine Learning Engineer |
| Pedro Tobias Souza Guerra | [@TobiasPedro1](https://github.com/TobiasPedro1) | Analista de Dados & Looker Studio |
| Vitor Antonio Silvestre | [@Vitorass0](https://github.com/Vitorass0) | Desenvolvedor Backend & API |

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

### Stack TÃ©cnica
- **Infraestrutura**: Terraform, GCP (Vertex AI Endpoints, BigQuery, Cloud Storage, Artifact Registry)
- **Backend**: Python 3.11+, FastAPI, Uvicorn, Pydantic
- **Dados**: ONS API, BigQuery, Cloud Storage (Parquet)
- **Observabilidade**: Cloud Monitoring, Cloud Logging, Budget Alerts
- **CI/CD**: GitHub Actions, Workload Identity Federation
- **Testes**: pytest, coverage â‰¥ 85%

### Fluxo de Dados
1. **IngestÃ£o**: Coleta dados ONS â†’ Cloud Storage (particionado) - *Vitor Silvestre, Pedro Tobias*
2. **Processamento**: BigQuery (tabelas externas â†’ Trusted â†’ Processed) - *Gustavo Wandereli*
3. **API**: FastAPI serve dados por data/perÃ­odo - *Vitor Silvestre*
4. **AnÃ¡lise**: Modelo de previsÃ£o (LSTM) implantado no Vertex AI Endpoints. O serviÃ§o busca features da camada Gold do BigQuery, gera as previsÃµes e salva os resultados de volta no BigQuery para monitoramento. - *Magno Sillas*
5. **VisualizaÃ§Ã£o**: Dashboard Looker Studio - *Pedro Tobias*

## ğŸš€ Como Rodar Localmente

### PrÃ©-requisitos
- Docker e Docker Compose
- Python 3.11+ (opcional, para desenvolvimento)
- Conta GCP com billing habilitado
- Git

### ğŸ³ OpÃ§Ã£o 1: Docker (Recomendado)

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/Sauter-University/sauter-university-2025-challenge.git
cd sauter-university-2025-challenge
```

2. **Suba o banco PostgreSQL (para desenvolvimento):**
```bash
docker-compose up -d
```

3. **Configure e execute a API:**
```bash
# Criar arquivo de ambiente (ainda nÃ£o existe .env.example)
# TODO: Criar src/api/.env com credenciais GCP

# Instalar dependÃªncias
cd src/api
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
pip install -r requirements.txt

# Executar API
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

4. **Acesse a aplicaÃ§Ã£o:**
- API: http://localhost:8000
- DocumentaÃ§Ã£o: http://localhost:8000/docs
- PostgreSQL: localhost:5432 (user: university, password: university)

### ğŸ OpÃ§Ã£o 2: Desenvolvimento Local

1. **Instale dependÃªncias:**
```bash
cd src/api
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

2. **Configure ambiente:**
```bash
cp .env.example .env
# Edite .env com suas credenciais GCP e configuraÃ§Ãµes
```

3. **Execute a API:**
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### âš™ï¸ ConfiguraÃ§Ã£o de Ambiente

#### VariÃ¡veis ObrigatÃ³rias (.env)
```bash
# ONS API
ONS_API_URL=https://dados.ons.org.br/api/3/action/package_show

# Google Cloud Storage
GCS_BUCKET_NAME=seu-bucket-name

# Credenciais GCP (escolha uma opÃ§Ã£o)
GOOGLE_CREDENTIALS_JSON='{"type":"service_account",...}'
# OU
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
API_AUTH_MODE=apikey
LOG_LEVEL=INFO
```

## ğŸ—ï¸ Deploy da Infraestrutura

### 1. Configurar Terraform
```bash
cd src/terraform
cp terraform.tfvars.example terraform.tfvars
# Configure suas variÃ¡veis GCP
```

### 2. Aplicar Infraestrutura
```bash
terraform init
terraform plan -out=tfplan
terraform apply tfplan
```

### 3. Verificar Recursos Criados
- Cloud Run service
- BigQuery datasets 
- Cloud Storage buckets
- Artifact Registry
- Budget e alertas
- IAM roles e service accounts

## ğŸ“Š Endpoints da API

### Principais Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/healthz` | Health check |
| `GET` | `/metrics` | MÃ©tricas Prometheus |
| `GET` | `/v1/ena/reservatorios/{id}/daily?date=YYYY-MM-DD` | Dados diÃ¡rios de reservatÃ³rio |
| `GET` | `/v1/ena/reservatorios/{id}/historico?start_date&end_date` | Dados histÃ³ricos |
| `GET` | `[https://modelo-ena-api-332613513827.us-central1.run.app/prever?data_base=2023-01-01](https://modelo-ena-api-332613513827.us-central1.run.app/prever?data_base=2023-01-01)` | PrevisÃ£o ML |

### Trilhos EspecÃ­ficos
**Trilho A (Modelo Preditivo):**
- `GET /prever?horizonte=30` (Endpoint implantado no Vertex AI que retorna a previsÃ£o para os prÃ³ximos N dias).

**Trilho B (Multi-Agente):**
- `POST /v1/agents/query` â†’ `{question: "..."}`

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Executar Testes
```bash
# Testes unitÃ¡rios
cd src/api
pytest tests/ --cov=. --cov-report=html

# Verificar cobertura (mÃ­nimo 85%)
coverage report --show-missing
```

### ValidaÃ§Ã£o de Qualidade
```bash
# Lint e formataÃ§Ã£o
ruff check src/ --fix
ruff format src/

# Type checking
mypy src/ --config-file=pyproject.toml

# Build Docker
docker build -t university-api .
```

### MÃ©tricas de Qualidade
- **Cobertura de testes**: â‰¥ 85%
- **Lint score**: 10/10 (ruff)
- **Type coverage**: 100% (mypy)
- **Performance**: API < 500ms p95

## ğŸ“ˆ Observabilidade e Monitoramento

### Dashboards e MÃ©tricas
- **Cloud Monitoring**: LatÃªncia, taxa de erro, QPS
- **Cloud Logging**: Logs estruturados JSON com trace_id
- **Budget Alerts**: 50%, 75%, 90% 100% do orÃ§amento R$ 300
- **SLO**: p95 < 500ms, taxa de erro < 1%

### Logs e Debugging
```bash
# Ver logs Cloud Run
gcloud logging read "resource.type=cloud_run_revision" --limit=50

# MÃ©tricas da aplicaÃ§Ã£o
curl http://localhost:8000/metrics
```

### Runbook para Incidentes

#### ğŸš¨ API NÃ£o Responde
1. Verificar health check: `GET /healthz`
2. Checar logs: Cloud Console â†’ Cloud Run â†’ Logs
3. Verificar recursos: CPU/Memory no Cloud Monitoring
4. Rollback se necessÃ¡rio: `gcloud run services update-traffic`

#### ğŸ’° Alerta de Custo
1. Verificar dashboard de billing
2. Identificar recursos com maior custo
3. Revisar queries BigQuery (slot usage)
4. Considerar pausar ingestÃ£o nÃ£o-crÃ­tica

## ğŸ” SeguranÃ§a

### Boas PrÃ¡ticas Implementadas
- âœ… **Secrets**: Uso de `.env` (nunca commitar credenciais)
- âœ… **IAM**: PrincÃ­pio do menor privilÃ©gio
- âœ… **WIF**: Workload Identity Federation (sem service account keys)
- âœ… **API**: Rate limiting e validaÃ§Ã£o de input
- âœ… **Network**: Cloud Run com ingress controlado

### PermissÃµes MÃ­nimas NecessÃ¡rias
```yaml
# Service Account para API
roles:
  - roles/bigquery.dataViewer
  - roles/storage.objectViewer
  - roles/cloudsql.client

# Service Account para CI/CD
roles:
  - roles/run.developer
  - roles/artifactregistry.writer
  - roles/iam.serviceAccountUser
```

## â˜ï¸ Google Cloud CLI (gcloud) - Resumo PrÃ¡tico

### ğŸ”§ **Setup Inicial (Uma vez por desenvolvedor)**
```bash
# Instalar gcloud CLI
curl https://sdk.cloud.google.com | bash && exec -l $SHELL

# Configurar projeto
gcloud auth login
gcloud config set project sauter-university-2025
gcloud auth application-default login  # Para desenvolvimento local
```

### ğŸ›¡ï¸ **PrÃ¡ticas de SeguranÃ§a Essenciais**

#### âœ… **O que FAZER:**
```bash
# Usar Application Default Credentials (desenvolvimento)
gcloud auth application-default login

# Verificar permissÃµes antes de executar
gcloud config list
gcloud projects test-iam-permissions sauter-university-2025 --permissions="run.services.create"

# Monitorar custos e atividades
gcloud logging read "severity>=WARNING" --limit=10
gcloud billing budgets list
```

#### âŒ **O que NUNCA fazer:**
```bash
# âŒ Commitar chaves JSON
git add service-account-key.json

# âŒ Usar service account keys em produÃ§Ã£o
gcloud auth activate-service-account --key-file=key.json

# âŒ Dar permissÃµes excessivas
gcloud projects add-iam-policy-binding --role="roles/owner"

# âŒ Expor serviÃ§os sem autenticaÃ§Ã£o
gcloud run deploy --allow-unauthenticated  # SÃ³ em dev!
```

### ğŸš¨ **Troubleshooting RÃ¡pido**
```bash
# Problemas de autenticaÃ§Ã£o
gcloud auth list && gcloud auth login

# Problemas de deploy
gcloud run services describe university-api --region=us-central1
gcloud logs read "severity>=ERROR" --limit=5

# Verificar configuraÃ§Ã£o
gcloud config list --all
gcloud info --run-diagnostics
```

## ğŸ—ï¸ Estrutura do Projeto

```text
/
â”œâ”€â”€ .github/workflows/       # CI/CD pipeline (ci.yaml, cd.yaml)
â”œâ”€â”€ .git/                   # Controle de versÃ£o Git
â”œâ”€â”€ .venv/                  # Ambiente virtual Python (local)
â”œâ”€â”€ doc/challenge/          # DocumentaÃ§Ã£o e diagramas
â”œâ”€â”€ img/                    # Imagens do projeto
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py         # AplicaÃ§Ã£o principal
â”‚   â”‚   â”œâ”€â”€ requirements.txt # DependÃªncias Python
â”‚   â”‚   â”œâ”€â”€ core/           # MÃ³dulos core (exceptions, logging, ons_client)
â”‚   â”‚   â”œâ”€â”€ models/         # Modelos de dados (basin.py)
â”‚   â”‚   â”œâ”€â”€ repositories/   # Camada de dados (basin_repository, gcs_repository)
â”‚   â”‚   â”œâ”€â”€ routers/        # Rotas da API (basin.py)
â”‚   â”‚   â””â”€â”€ services/       # LÃ³gica de negÃ³cio (basin_service)
â”‚   â”œâ”€â”€ querys/             # Queries SQL BigQuery
â”‚   â”‚   â”œâ”€â”€ create_ena_bronze.sql
â”‚   â”‚   â”œâ”€â”€ create_ena_silver.sql
â”‚   â”‚   â””â”€â”€ create_external_table.sql
â”‚   â””â”€â”€ terraform/          # Infraestrutura como cÃ³digo
â”‚       â”œâ”€â”€ modules/        # MÃ³dulos Terraform
â”‚       â”‚   â”œâ”€â”€ artifact_registry/
â”‚       â”‚   â”œâ”€â”€ bigquery/
â”‚       â”‚   â”œâ”€â”€ budget/
â”‚       â”‚   â”œâ”€â”€ cloud_run/
â”‚       â”‚   â”œâ”€â”€ cloud_storage/
â”‚       â”‚   â”œâ”€â”€ iam/
â”‚       â”‚   â”œâ”€â”€ monitoring/
â”‚       â”‚   â”œâ”€â”€ security_policies/
â”‚       â”‚   â””â”€â”€ wif/        # Workload Identity Federation
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â”œâ”€â”€ outputs.tf
â”‚       â””â”€â”€ terraform.tfvars.example
â”œâ”€â”€ docker-compose.yml      # PostgreSQL para desenvolvimento
â”œâ”€â”€ Dockerfile              # ContainerizaÃ§Ã£o da API
â”œâ”€â”€ .gitignore              # Arquivos ignorados pelo Git
â””â”€â”€ README.md               # Este arquivo
```

## ğŸ“‹ Casos de Uso

### ğŸ¯ Casos de Uso PrioritÃ¡rios

1. **[P0] IngestÃ£o de Dados ONS**
   - Como analista, quero dados atualizados de ENA para anÃ¡lise
   - CritÃ©rio: Dados ingeridos diariamente com < 2h de atraso

2. **[P0] API de Consulta HistÃ³rica**
   - Como usuÃ¡rio, quero consultar dados por perÃ­odo especÃ­fico
   - CritÃ©rio: Resposta < 500ms para consultas histÃ³ricas

3. **[P1] Dashboard AnalÃ­tico**
   - Como gestor, quero visualizar tendÃªncias e KPIs
   - CritÃ©rio: Dashboard atualizado em tempo real

4. **[P1] AnÃ¡lise AvanÃ§ada (Trilho A ou B)**
   - Como especialista, quero previsÃµes/insights inteligentes
   - CritÃ©rio: AcurÃ¡cia > 70% ou respostas contextuais relevantes

### ğŸ”„ CI/CD Pipeline

#### Continuous Integration
- **Trigger**: Pull Request para `main`
- **Steps**: Lint â†’ Type Check â†’ Tests â†’ Coverage â†’ Build
- **Gates**: Cobertura â‰¥ 85%, todos os checks verdes

#### Continuous Deployment  
- **Trigger**: Push para `main`
- **Steps**: Build â†’ Push Registry â†’ Deploy Cloud Run â†’ Health Check
- **Rollback**: AutomÃ¡tico em caso de falha no health check

```bash
# Deploy manual (se necessÃ¡rio)
gcloud run deploy university-api \
  --image=gcr.io/PROJECT/university-api:latest \
  --region=us-central1 \
  --allow-unauthenticated
```

## ğŸ¨ Dashboard e Analytics

### Looker Studio Dashboard
- **ResponsÃ¡vel**: Pedro Tobias (Analista de Dados)
- **URL**: [Dashboard Sauter University](https://lookerstudio.google.com/reporting/6230a252-40a5-4b56-9f18-8c5b1289bd72)
- **Fonte de Dados**: Views otimizadas do BigQuery
- **GrÃ¡ficos**: SÃ©ries temporais ENA, distribuiÃ§Ãµes, correlaÃ§Ãµes entre reservatÃ³rios
- **AtualizaÃ§Ã£o**: AutomÃ¡tica a cada 1 hora
- **MÃ©tricas**: KPIs operacionais, previsÃµes ML, alertas de anomalias

### Justificativa dos GrÃ¡ficos (Pedro Tobias)
1. **SÃ©rie temporal ENA**: TendÃªncias sazonais e anomalias
2. **Mapas de calor**: CorrelaÃ§Ã£o entre reservatÃ³rios  
3. **DistribuiÃ§Ãµes**: AnÃ¡lise estatÃ­stica dos volumes
4. **Indicadores KPI**: Status operacional em tempo real

## ğŸ“ Registro de DecisÃµes Arquiteturais (ADR)

### ADR-001: Escolha da Cloud Platform (2025-09-25)
- **DecisÃ£o**: Google Cloud Platform
- **Alternativas**: AWS, Azure
- **Justificativa**: BigQuery para analytics, Cloud Run serverless, crÃ©ditos educacionais
- **ResponsÃ¡vel**: Genildo Burgos (Dev Ops)

### ADR-002: Framework de API Backend (2025-09-25)
- **DecisÃ£o**: FastAPI com Pydantic para validaÃ§Ã£o
- **Alternativas**: Django REST Framework, Flask-RESTful
- **Justificativa**: Performance superior, documentaÃ§Ã£o automÃ¡tica OpenAPI, type hints nativos, async support
- **ResponsÃ¡vel**: Vitor Silvestre (Backend & API)

### ADR-003: EstratÃ©gia de Pipeline de Dados (2025-09-25)
- **DecisÃ£o**: Arquitetura Medallion (Bronze â†’ Silver â†’ Gold) no BigQuery
- **Alternativas**: Data Lake simples, Star Schema tradicional
- **Justificativa**: SeparaÃ§Ã£o clara de responsabilidades, data quality por camadas, escalabilidade
- **ResponsÃ¡vel**: Gustavo Wanderley (Engenharia de Dados)

### ADR-004: Trilho de AnÃ¡lise AvanÃ§ada (2025-09-25)
- **DecisÃ£o**: Modelo Preditivo de Machine Learning para previsÃ£o de ENA
- **Alternativas**: Sistema Multi-Agente com RAG
- **Justificativa**: Expertise da equipe em ML, dados estruturados ONS ideais para previsÃ£o temporal, acurÃ¡cia mensurÃ¡vel > 70%
- **ResponsÃ¡vel**: Magno Silas (Data Engineering & ML)

### ADR-005: Plataforma de Dashboard e VisualizaÃ§Ã£o (2025-09-25)
- **DecisÃ£o**: Looker Studio para dashboard analÃ­tico
- **Alternativas**: Tableau, Power BI, Grafana
- **Justificativa**: IntegraÃ§Ã£o nativa BigQuery, gratuito, facilidade de compartilhamento, templates prontos
- **ResponsÃ¡vel**: Pedro Tobias (Analista de Dados & QA)


## ğŸ—“ï¸ Changelog

### v1.0.0 (2025-09-25)
- âœ… Setup inicial do repositÃ³rio
- âœ… ConfiguraÃ§Ã£o Docker e Docker Compose
- âœ… Estrutura base da API FastAPI
- âœ… Pipeline CI/CD bÃ¡sico
- âœ… DocumentaÃ§Ã£o README
- âœ… ImplementaÃ§Ã£o da ingestÃ£o ONS
- âœ… Setup completo BigQuery  
- âœ… Endpoints da API v1
- âœ… Escolha e implementaÃ§Ã£o do trilho
- âœ… Dashboard Looker Studio
- âœ… Testes e cobertura â‰¥ 85%

## ğŸ¤ Como Contribuir

1. **Fork** o repositÃ³rio
2. **Crie** uma branch: `git checkout -b feat/nova-funcionalidade`
3. **Commit** seguindo [Conventional Commits](https://conventionalcommits.org/)
4. **Push** para a branch: `git push origin feat/nova-funcionalidade`
5. **Abra** um Pull Request

### PadrÃµes de Commit
```
feat: adiciona endpoint de previsÃ£o
fix: corrige validaÃ§Ã£o de datas
docs: atualiza README com instruÃ§Ãµes
test: adiciona testes para ingestÃ£o
```

## ğŸ“ Suporte e Contato

- **Issues**: [GitHub Issues](https://github.com/Sauter-University/sauter-university-2025-challenge/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Sauter-University/sauter-university-2025-challenge/discussions)
- **Contato**: Contato atravÃ©s dos perfis GitHub da equipe


---


**ğŸ“ Sauter University 2025 Challenge** - Desenvolvido com â˜• pela equipe 


